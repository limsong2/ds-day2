{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification report\n",
    "\n",
    "A Classification report is used to measure the __quality of predictions__ from a classification algorithm. <br>\n",
    "More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report.<br><br> \n",
    "\n",
    "- True Negative (TN): when a case was negative and predicted negative\n",
    "- True Positive (TP): when a case was positive and predicted positive\n",
    "- False Negative (FN): when a case was positive but predicted negative\n",
    "- False Positive (FP): when a case was negative but predicted positive\n",
    "\n",
    "\n",
    "Classification report of Iris dataset using the SVM algorithm:<br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=2, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        16\n",
      "Iris-versicolor       1.00      0.94      0.97        18\n",
      " Iris-virginica       0.92      1.00      0.96        11\n",
      "\n",
      "       accuracy                           0.98        45\n",
      "      macro avg       0.97      0.98      0.98        45\n",
      "   weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "dataset = pd.read_csv('datasets/iris.data', names=colnames)\n",
    "X = dataset.drop('Class', axis=1)\n",
    "y = dataset['Class']\n",
    "X.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "svclassifier = SVC(kernel='rbf', degree=2, gamma='auto')\n",
    "svclassifier.fit(X_train, y_train)\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=y.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The report shows the main classification metrics __precision__, __recall__ and __f1-score__ on a per-class basis. \n",
    "\n",
    "### Precision (what percent of your predictions were correct?)\n",
    "\n",
    "__Precision__ is the ability of a classifier not to label an instance positive that is actually negative (i.e. the accuracy of positive predictions).<br>\n",
    "For each class it is defined as the ratio of true positives to the sum of true and false positives.\n",
    "<br>\n",
    "Precision = TP/(TP + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(f\"Precision score: {precision_score(y_test, y_pred, average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Recall (What percent of the positive cases did you catch?) \n",
    "\n",
    "__Recall__ is the ability of a classifier to find all positive instances (i.e. the fraction of positives that were correctly identified).<br> \n",
    "For each class it is defined as the ratio of true positives to the sum of true positives and false negatives.<br>\n",
    "\n",
    "Recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(f\"Recall score: {recall_score(y_test,y_pred,average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score (What percent of positive predictions were correct?)\n",
    " \n",
    "The __F1 score__ is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. <br>\n",
    "Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. <br>\n",
    "As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "<br>\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 Score: {f1_score(y_test,y_pred,average='micro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other reported information include: <br>\n",
    "- __macro average__ (averaging the unweighted mean per label), \n",
    "- __weighted average__ (averaging the support-weighted mean per label)\n",
    "- __accuracy__ (the fraction of predictions our model got right: (tp+tn)/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "A __confusion matrix__ visualises classification accuracy and errors made by a machine learning model. <br>\n",
    "They are especially useful where there are multiple classification categories. <br>\n",
    "Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa). \n",
    "\n",
    "The Scikit-Learn function __confusion_matrix()__ returns a confusion matrix and it is possible to use a plotting library to plot it if we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 11]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, '0'), Text(0, 1.5, '1'), Text(0, 2.5, '2')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, '0'), Text(1.5, 0, '1'), Text(2.5, 0, '2')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3.0, 0.0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True label')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predicted label')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Confusion Matrix')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(cnf_matrix)\n",
    "hmap=sns.heatmap(cnf_matrix, annot=True, fmt='d')\n",
    "hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=45, ha='right')\n",
    "bottom, top = hmap.get_ylim() # to correct a bug with matplotlib 3.1.1\n",
    "hmap.set_ylim(bottom + 0.5, top - 0.5) # to correct a bug with matplotlib 3.1.1\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.title('Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Error Metrics\n",
    "\n",
    "The quality of a __regression model__ is how well its predictions match up against actual values.\n",
    "<br>Several error metrics exist to judge the quality of a model and enable us to compare regresssions against other regressions with different parameters.<br>\n",
    "Several kind of regressions do exist, here are some metrics related to the linear regression:\n",
    "\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Square Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "\n",
    "\n",
    "### Mean absolute error\n",
    "The __mean absolute error (MAE)__ calculate the residual for every data point, taking only the absolute value of each so that negative and positive residuals do not cancel out, and then take the average of all these residuals.<br>\n",
    "The picture below is a graphical description of the MAE. The green line represents our model’s predictions, and the blue points represent our data.\n",
    "\n",
    "<img src=\"mae.jpg\" alt=\"Mean Absolute Error\" title=\"MAE\" width=400 height=400 />\n",
    "\n",
    "A small MAE (compared to the feature range) suggests the model is great at prediction (0 means that your model is a perfect predictor), while a large MAE suggests that your model may have trouble in certain areas.\n",
    "\n",
    "### Mean square error\n",
    "\n",
    "The __mean square error (MSE)__ is just like the MAE, but squares the difference before summing them all instead of using the absolute value.<br> \n",
    "Since the errors are squared before they are averaged, the MSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable. <br>\n",
    "__Note__: outliers in the data will contribute to much higher total error in the MSE than they would the MAE.\n",
    "\n",
    "### Root Mean square error\n",
    "\n",
    "The __root mean squared error (RMSE)__ is the square root of the MSE. <br>\n",
    "Because the MSE is squared, its units do not match that of the original output. RMSE converts the error metric back into similar units, making interpretation easier. <br>\n",
    "Since the MSE and RMSE both square the residual, they are similarly affected by outliers. <br>\n",
    "The RMSE is analogous to the standard deviation (MSE to variance) and is a measure of how large your residuals are spread out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
